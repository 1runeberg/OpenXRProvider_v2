/* Copyright 2021, 2022, 2023 Rune Berg (GitHub: https://github.com/1runeberg, Twitter: https://twitter.com/1runeberg, YouTube: https://www.youtube.com/@1RuneBerg)
 *
 *  SPDX-License-Identifier: MIT
 *
 *  Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
 *
 *  1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 *
 *  2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the
 *     documentation and/or other materials provided with the distribution.
 *
 *  3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this
 *     software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 *  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS
 *  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
 *  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 *  LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
 *  DAMAGE.
 *
 */

// App defines
#define APP_NAME "sample_09_hidden_worlds"
#define ENGINE_NAME "openxr_provider"
#define LOG_CATEGORY_DEMO "OpenXRProviderDemo"

// Generated by cmake by populating project_config.h.in
#include "project_config.h"

#include <cstdlib>
#include <iomanip>
#include <iostream>

#include <openxr_provider.h>
#include <xrvk/xrvk.hpp>

#include "xrvk/xrvk.hpp"

// Event data packet sent by the openxr runtime during polling
XrEventDataBaseHeader *g_xrEventDataBaseheader = nullptr;

// Pointer to session handling object of the openxr provider library
oxr::Session *g_pSession = nullptr;

// Pointer to input handling object of the openxr provider library
oxr::Input *g_pInput = nullptr;

// Future for input thread
std::future< XrResult > g_inputThread;

// Current openxr session state
XrSessionState g_sessionState = XR_SESSION_STATE_UNKNOWN;

// Latest openxr framestate - this is filled in on the render call
XrFrameState g_xrFrameState { XR_TYPE_FRAME_STATE };

// Projection views and layers to be rendered
std::vector< XrCompositionLayerProjectionView > g_vecFrameLayerProjectionViews;
std::vector< XrCompositionLayerBaseHeader * > g_vecFrameLayers;

// Pointer to the the xrvk renderer class
std::unique_ptr< xrvk::Render > g_pRender = nullptr;

// ====
// OpenXR Reference Cube
// SPDX-License-Identifier: Apache-2.0
std::vector< unsigned short > g_vecCubeIndices = {
	0,	1,	2,	3,	4,	5,	// -X
	6,	7,	8,	9,	10, 11, // +X
	12, 13, 14, 15, 16, 17, // -Y
	18, 19, 20, 21, 22, 23, // +Y
	24, 25, 26, 27, 28, 29, // -Z
	30, 31, 32, 33, 34, 35, // +Z
};

std::vector< Shapes::Vertex > g_vecCubeVertices = {
	CUBE_SIDE( Shapes::LTB, Shapes::LBF, Shapes::LBB, Shapes::LTB, Shapes::LTF, Shapes::LBF, Shapes::DarkRed )	 // -X
	CUBE_SIDE( Shapes::RTB, Shapes::RBB, Shapes::RBF, Shapes::RTB, Shapes::RBF, Shapes::RTF, Shapes::Red )		 // +X
	CUBE_SIDE( Shapes::LBB, Shapes::LBF, Shapes::RBF, Shapes::LBB, Shapes::RBF, Shapes::RBB, Shapes::DarkGreen ) // -Y
	CUBE_SIDE( Shapes::LTB, Shapes::RTB, Shapes::RTF, Shapes::LTB, Shapes::RTF, Shapes::LTF, Shapes::Green )	 // +Y
	CUBE_SIDE( Shapes::LBB, Shapes::RBB, Shapes::RTB, Shapes::LBB, Shapes::RTB, Shapes::LTB, Shapes::DarkBlue )	 // -Z
	CUBE_SIDE( Shapes::LBF, Shapes::LTF, Shapes::RTF, Shapes::LBF, Shapes::RTF, Shapes::RBF, Shapes::Blue )		 // +Z
};
// ==== end of OpenXR Reference Cube

// Hand tracking extension implementation, if present
oxr::ExtHandTracking *g_extHandTracking = nullptr;

// Eye tracking extension implementation, if present
oxr::ExtEyeGaze *g_extEyeGaze = nullptr;

// FB Passthrough extension implementation, if present
oxr::ExtFBPassthrough *g_extFBPassthrough = nullptr;

// FB Display refresh rate extension implementation, if present
oxr::ExtFBRefreshRate *g_extFBRefreshRate = nullptr;

// Controller state
bool g_bLeftControllerActive = false;
bool g_bRightControllerActive = false;

// Eye gaze
bool g_bEyeGazeActive = false;
bool g_bXrayModeOn = false;

uint32_t g_unXray = 0;
uint32_t g_unStencilFillPipelineIndex = 0;

std::vector< uint32_t > g_vecHiddenWorlds;
std::vector< uint32_t > g_vecFoundWorlds;

oxr::Action *g_pActionEyePose = nullptr;
oxr::Action *g_pActionEyePoseBackup = nullptr;

XrSpace g_spaceHmd = XR_NULL_HANDLE;

// Animation
uint32_t g_unAnimatedModel = 0;
float g_fCurrentRefreshRate = 0.0f;
float g_fAnimSpeed = 0.011f; // base rate is 80hz = .01f

// Passthrough adjustments
bool g_bSaturationAdjustmentActivated = false;
float g_fSaturationValueOnActivation = 0.0f;
float g_fCurrentSaturationValue = 0.0f;

// Clap mechanic
bool g_bClapActive = false;

// Reference to the pose action (used for aim pose painting)
oxr::Action *g_ControllerPoseAction = nullptr;

// Reference to haptic action
oxr::Action *g_hapticAction = nullptr;

// Renderable index for the hands
uint32_t g_unLeftHandIndex = 0;
uint32_t g_unRightHandIndex = 0;

// Gesture constants
static const float k_fGestureActivationThreshold = 0.025f;
static const float k_fPinchGestureActivationThreshold = 0.015f;
static const float k_fClapActivationThreshold = 0.07f;
static const float k_fSaturationAdjustmentStride = 0.1f;

/**
 * These are utility functions for the extensions we will be using in this demo
 */

inline void HideHandShapes()
{
	uint32_t unTotalHandJoints = XR_HAND_JOINT_COUNT_EXT * 2;

	// left hand will use the first XR_HAND_JOINT_COUNT_EXT indices
	// right hand will use specHandJointIndex + XR_HAND_JOINT_COUNT_EXT indices
	for ( uint32_t i = 0; i < unTotalHandJoints; i++ )
	{
		g_pRender->vecShapes[ i ]->scale = { 0.f, 0.f, 0.f };
	}
}

inline void PopulateHandShapes( Shapes::Shape *shapePalm )
{
	assert( g_pRender );
	assert( shapePalm );

	// a cube per joint per hand - we'll match the indices with the hand tracking extension's
	// so we can easily refer to them later on to update the current tracked poses
	uint32_t unTotalHandJoints = XR_HAND_JOINT_COUNT_EXT * 2;
	g_pRender->vecShapes.resize( unTotalHandJoints );

	// zero out the scale so cubes won't immediately appear until after the first frame of poses come in
	shapePalm->scale = { 0.0f, 0.0f, 0.0f };

	// XR_HAND_JOINT_PALM_EXT (0) - Use as a reference
	g_pRender->vecShapes[ XR_HAND_JOINT_PALM_EXT ] = shapePalm;

	// left hand will use the first XR_HAND_JOINT_COUNT_EXT indices
	// right hand will use specHandJointIndex + XR_HAND_JOINT_COUNT_EXT indices
	for ( uint32_t i = 1; i < unTotalHandJoints; i++ )
	{
		g_pRender->vecShapes[ i ] = shapePalm->Duplicate();
	}
}

inline void UpdateHandJoints( XrHandEXT hand, XrHandJointLocationEXT *handJoints )
{
	uint8_t unOffset = hand == XR_HAND_LEFT_EXT ? 0 : XR_HAND_JOINT_COUNT_EXT;

	for ( uint32_t i = 0; i < XR_HAND_JOINT_COUNT_EXT; i++ )
	{
		if ( ( handJoints[ i ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
		{
			g_pRender->vecShapes[ i + unOffset ]->pose = handJoints[ i ].pose;
			g_pRender->vecShapes[ i + unOffset ]->scale = { handJoints[ i ].radius, handJoints[ i ].radius, handJoints[ i ].radius };
		}
	}
}

inline void UpdateHandTrackingPoses( XrFrameState *frameState )
{
	if ( g_extHandTracking )
	{
		// Update the hand joints poses for this frame
		g_extHandTracking->LocateHandJoints( XR_HAND_LEFT_EXT, g_pSession->GetAppSpace(), frameState->predictedDisplayTime );
		g_extHandTracking->LocateHandJoints( XR_HAND_RIGHT_EXT, g_pSession->GetAppSpace(), frameState->predictedDisplayTime );

		// Retrieve updated hand poses
		XrHandJointLocationsEXT *leftHand = g_extHandTracking->GetHandJointLocations( XR_HAND_LEFT_EXT );
		XrHandJointLocationsEXT *rightHand = g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT );

		// Finally, update cube poses representing the hand joints
		if ( leftHand->isActive )
			UpdateHandJoints( XR_HAND_LEFT_EXT, leftHand->jointLocations );

		if ( rightHand->isActive )
			UpdateHandJoints( XR_HAND_RIGHT_EXT, g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT )->jointLocations );
	}
}

inline bool IsTwoHandedGestureActive(
	XrHandJointEXT leftJointA,
	XrHandJointEXT leftJointB,
	XrHandJointEXT rightJointA,
	XrHandJointEXT rightJointB,
	XrVector3f *outReferencePosition_Left,
	XrVector3f *outReferencePosition_Right,
	bool *outActivated,
	float *fCacheValue )
{
	// Get latest hand joints
	XrHandJointLocationsEXT *leftHand = g_extHandTracking->GetHandJointLocations( XR_HAND_LEFT_EXT );
	XrHandJointLocationsEXT *rightHand = g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT );

	XrHandJointLocationEXT *leftJoints = leftHand->jointLocations;
	XrHandJointLocationEXT *rightJoints = rightHand->jointLocations;

	// Check if both left and right hands are tracking
	// and the provided joint a and joint b on both hands have valid positions
	if ( leftHand->isActive && rightHand->isActive && ( leftJoints[ leftJointA ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
		 ( leftJoints[ leftJointB ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 && ( rightJoints[ rightJointA ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
		 ( rightJoints[ rightJointB ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
	{
		// Check gesture
		float fDistance = 0.0f;

		*outReferencePosition_Left = leftJoints[ leftJointB ].pose.position;
		XrVector3f_Distance( &fDistance, &leftJoints[ leftJointA ].pose.position, outReferencePosition_Left );

		if ( fDistance < k_fGestureActivationThreshold )
		{
			*outReferencePosition_Right = rightJoints[ rightJointB ].pose.position;
			XrVector3f_Distance( &fDistance, &rightJoints[ rightJointA ].pose.position, outReferencePosition_Right );

			if ( fDistance < k_fGestureActivationThreshold )
			{
				*outActivated = true;
				return true;
			}
		}
	}

	*outActivated = false;
	*fCacheValue = 0.0f;
	return false;
}

inline bool IsSaturationAdjustmentActive( XrVector3f *outThumbPosition_Left, XrVector3f *outThumbPosition_Right )
{
	// Gesture - ring and thumb tips are touching on both hands
	return IsTwoHandedGestureActive(
		XR_HAND_JOINT_RING_TIP_EXT,
		XR_HAND_JOINT_THUMB_TIP_EXT,
		XR_HAND_JOINT_RING_TIP_EXT,
		XR_HAND_JOINT_THUMB_TIP_EXT,
		outThumbPosition_Left,
		outThumbPosition_Right,
		&g_bSaturationAdjustmentActivated,
		&g_fSaturationValueOnActivation );
}

inline void AdjustPassthroughSaturation( float fCurrentSaturationValue )
{
	// Check for required extensions
	if ( g_extFBPassthrough == nullptr )
		return;

	g_fCurrentSaturationValue = g_fCurrentSaturationValue < 0.0f ? 0.0f : fCurrentSaturationValue;
	g_extFBPassthrough->SetModeToBCS( 0.0f, 1.0f, g_fCurrentSaturationValue );
}

inline void AdjustPassthroughSaturation()
{
	if ( g_extHandTracking == nullptr )
		return;

	// Check if gesture was activated on a previous frame
	bool bGestureActivedOnPreviousFrame = g_bSaturationAdjustmentActivated;

	// Check if gesture is active in this frame
	XrVector3f leftThumb, rightThumb;
	if ( IsSaturationAdjustmentActive( &leftThumb, &rightThumb ) )
	{
		// Gesture was activated on this frame, cache the distance
		if ( !bGestureActivedOnPreviousFrame )
		{
			XrVector3f_Distance( &g_fSaturationValueOnActivation, &leftThumb, &rightThumb );
		}

		// Adjust saturation based on distance and stride
		float currentDistance = 0.0f;
		XrVector3f_Distance( &currentDistance, &leftThumb, &rightThumb );

		float fGestureDistanceFromPreviousFrame = currentDistance - g_fSaturationValueOnActivation;
		if ( abs( fGestureDistanceFromPreviousFrame ) < k_fSaturationAdjustmentStride )
			return;

		g_fCurrentSaturationValue = fGestureDistanceFromPreviousFrame * k_fSaturationAdjustmentStride * 80;
		AdjustPassthroughSaturation( g_fCurrentSaturationValue );
	}
}

inline void UpdateXrayAreaSpace()
{
	// if eye gaze is active, set to eye gaze pose
	if ( g_extEyeGaze && g_bEyeGazeActive )
	{
		g_pRender->vecRenderSectors[ g_unXray ]->xrSpace = g_pActionEyePose->vecActionSpaces[ 0 ];
		return;
	}

	// otherwise, set to controller aim pose with some offset
	if ( g_bLeftControllerActive || g_bRightControllerActive )
	{
		g_pRender->vecRenderSectors[ g_unXray ]->xrSpace = g_pActionEyePoseBackup->vecActionSpaces[ 0 ];
	}
	else
	{
		g_pRender->vecRenderSectors[ g_unXray ]->xrSpace = XR_NULL_HANDLE;
	}
}

inline void UpdateXrayAssetsVisibility()
{
	// clear all found worlds if user has found all of them
	if ( g_bXrayModeOn && g_vecFoundWorlds.size() == g_vecHiddenWorlds.size() )
		g_vecFoundWorlds.clear();

	// Set xray area visibility
	g_pRender->vecRenderSectors[ g_unXray ]->bIsVisible = g_bXrayModeOn;

	for ( auto index : g_vecHiddenWorlds )
	{
		// update visibility of hidden world if not yet found
		if ( std::find( g_vecFoundWorlds.begin(), g_vecFoundWorlds.end(), index ) == g_vecFoundWorlds.end() )
			g_pRender->vecRenderSectors[ index ]->bIsVisible = g_bXrayModeOn;
	}
}

inline void SwitchHiddenWorldGraphicsPipelines()
{
	// only if xray mnode is on
	if ( !g_bXrayModeOn )
		return;

	// check distance between player and hidden world - discarding y-axis (height)
	for ( auto index : g_vecHiddenWorlds )
	{
		// Get hmd location
		XrSpaceLocation hmdSpaceLocation { XR_TYPE_SPACE_LOCATION };
		g_pSession->LocateSpace( g_pSession->GetAppSpace(), g_spaceHmd, g_xrFrameState.predictedDisplayTime, &hmdSpaceLocation );

		// discard player height
		hmdSpaceLocation.pose.position.y = 0;

		float dist = 0.f;
		XrVector3f_Distance( &dist, &hmdSpaceLocation.pose.position, &g_pRender->vecRenderSectors[ index ]->currentPose.position );

		// check distance and make sure it's not been found yet
		if ( dist < 1.5f && std::find( g_vecFoundWorlds.begin(), g_vecFoundWorlds.end(), index ) == g_vecFoundWorlds.end() )
		{
			// use default/pbr
			g_bXrayModeOn = false;
			UpdateXrayAssetsVisibility();

			g_pRender->vecRenderSectors[ index ]->vkPipeline = VK_NULL_HANDLE;
			g_pRender->vecRenderSectors[ index ]->bIsVisible = true;

			// Add to found worlds
			g_vecFoundWorlds.push_back( index );
		}
		else
		{
			// use stencil fill
			if ( std::find( g_vecFoundWorlds.begin(), g_vecFoundWorlds.end(), index ) == g_vecFoundWorlds.end() )
				g_pRender->vecRenderSectors[ index ]->vkPipeline = g_pRender->GetCustomPipelines()[ g_unStencilFillPipelineIndex ];
		}
	}
}

inline void Clap()
{
	// Check for required extensions
	if ( g_extHandTracking == nullptr )
		return;

	// Get latest hand joints
	XrHandJointLocationsEXT *leftHand = g_extHandTracking->GetHandJointLocations( XR_HAND_LEFT_EXT );
	XrHandJointLocationsEXT *rightHand = g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT );

	// Gesture: palms of left and right hands are touching
	if ( leftHand->isActive && rightHand->isActive && ( leftHand->jointLocations[ XR_HAND_JOINT_PALM_EXT ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
		 ( rightHand->jointLocations[ XR_HAND_JOINT_PALM_EXT ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
	{
		float fDistance = 0.0f;
		XrVector3f_Distance( &fDistance, &leftHand->jointLocations[ XR_HAND_JOINT_PALM_EXT ].pose.position, &rightHand->jointLocations[ XR_HAND_JOINT_PALM_EXT ].pose.position );

		if ( fDistance < k_fClapActivationThreshold )
		{
			// Gesture activated - set the previous clap state for checking on successive frame
			g_bClapActive = true;
			return;
		}

		// Hands are active but not in clap gesture
		if ( g_bClapActive )
		{
			// If previous clap state is true, then toggle xray mode
			g_bXrayModeOn = g_bXrayModeOn ? false : true;
			UpdateXrayAssetsVisibility();
			UpdateXrayAreaSpace();

			g_bClapActive = false;
			return;
		}
	}

	// Hands were inactive or not giving valid data
	g_bClapActive = false;
}

inline void Pinch( XrHandEXT hand )
{
	// Defer to eye tracking if available
	if ( g_extEyeGaze && g_bEyeGazeActive )
		return;

	// Defer to controller if available
	if ( ( hand == XR_HAND_LEFT_EXT && g_bLeftControllerActive ) || ( hand == XR_HAND_RIGHT_EXT && g_bRightControllerActive ) )
	{
		// Show hand models if passthrough isn't available
		if ( !g_extFBPassthrough )
			g_pRender->vecRenderSectors[ hand == XR_HAND_LEFT_EXT ? g_unLeftHandIndex : g_unRightHandIndex ]->bIsVisible = true;

		// Hide hand shapes
		HideHandShapes();

		return;
	}

	// Check if hand tracking is available
	if ( g_extHandTracking )
	{
		// Hide hand models
		if ( g_extHandTracking )
			g_pRender->vecRenderSectors[ hand == XR_HAND_LEFT_EXT ? g_unLeftHandIndex : g_unRightHandIndex ]->bIsVisible = false;

		// Get latest hand joints
		XrHandJointLocationsEXT *joints = g_extHandTracking->GetHandJointLocations( hand );

		// Check if index tip and thumb tips have valid locations
		if ( joints->isActive && ( joints->jointLocations[ XR_HAND_JOINT_INDEX_TIP_EXT ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
			 ( joints->jointLocations[ XR_HAND_JOINT_THUMB_TIP_EXT ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
		{
			// Pinch gesture - if index and thumb tips meet
			float fDistance = 0.0f;
			XrVector3f_Distance( &fDistance, &joints->jointLocations[ XR_HAND_JOINT_INDEX_TIP_EXT ].pose.position, &joints->jointLocations[ XR_HAND_JOINT_THUMB_TIP_EXT ].pose.position );

			if ( fDistance < k_fPinchGestureActivationThreshold )
			{
				// Enable and update xray area location
				if ( !g_bXrayModeOn )
				{
					g_bXrayModeOn = true;
					UpdateXrayAssetsVisibility();
				}

				g_pRender->vecRenderSectors[ g_unXray ]->xrSpace = XR_NULL_HANDLE;
				g_pRender->vecRenderSectors[ g_unXray ]->currentPose = joints->jointLocations[ XR_HAND_JOINT_THUMB_TIP_EXT ].pose;
			}
		}
	}
}

inline void UpdateAnimSpeed()
{
	if ( g_fCurrentRefreshRate <= 0.0f )
	{
		// 90hz
		g_fAnimSpeed = ( 80.f / 90.f ) * 0.01f;
	}
	else
	{
		g_fAnimSpeed = ( 80.0f / g_fCurrentRefreshRate ) * 0.01f;
	}

	// update model animation rate, if available
	if ( !g_pRender->vecRenderSectors.empty() && g_unAnimatedModel < g_pRender->vecRenderSectors.size() )
	{
		g_pRender->vecRenderSectors[ g_unAnimatedModel ]->fAnimSpeed = g_fAnimSpeed;
	}
}

/**
 * These are the action functions that will be called by the input system
 */

inline void ActionAdjustSaturation( oxr::Action *pAction, uint32_t unActionStateIndex )
{
	// As there's finer control with thumbsticks vs gestures, we'll lower adjustment stride
	if ( pAction->vecActionStates[ unActionStateIndex ].stateFloat.currentState > 0.5f )
	{
		AdjustPassthroughSaturation( g_fCurrentSaturationValue + ( k_fSaturationAdjustmentStride / 5 ) );
	}
	else if ( pAction->vecActionStates[ unActionStateIndex ].stateFloat.currentState < -0.5f )
	{
		AdjustPassthroughSaturation( g_fCurrentSaturationValue - ( k_fSaturationAdjustmentStride / 5 ) );
	}
}

inline void ActionSetControllerIsActive( oxr::Action *pAction, uint32_t unActionStateIndex )
{
	if ( pAction->vecActionStates[ unActionStateIndex ].statePose.isActive )
	{
		if ( unActionStateIndex == 0 )
			g_bLeftControllerActive = true;
		else
			g_bRightControllerActive = true;
	}
	else
	{
		if ( unActionStateIndex == 0 )
			g_bLeftControllerActive = false;
		else
			g_bRightControllerActive = false;
	}
}

inline void ActionActivateXrayMode( oxr::Action *pAction, uint32_t unActionStateIndex )
{
	// toggle xray mode
	if ( pAction->vecActionStates[ unActionStateIndex ].stateBoolean.currentState )
		g_bXrayModeOn = g_bXrayModeOn ? false : true;

	// update xray area spawm space
	if ( g_bXrayModeOn )
	{
		if ( g_extEyeGaze && g_bEyeGazeActive )
		{
			// 	if eye gaze is available, set xray area space to eye gaze space
			g_pRender->vecRenderSectors[ g_unXray ]->xrSpace = g_pActionEyePose->vecActionSpaces[ 0 ];
		}
		else
		{
			// otherwise, use backup (controller aim pose with a bit of offset)
			g_pRender->vecRenderSectors[ g_unXray ]->xrSpace = g_pActionEyePoseBackup->vecActionSpaces[ unActionStateIndex ];
		}

		// Apply haptics - we'll use the openxr provider library's default amplitude and frequency
		uint64_t unDuration = 1000000000; // 1 second in nanoseconds

		if ( unActionStateIndex == 0 && g_bLeftControllerActive )
		{
			g_pInput->GenerateHaptic( g_hapticAction->xrActionHandle, g_hapticAction->vecSubactionpaths[ 0 ], unDuration );
		}
		else if ( unActionStateIndex == 1 && g_bRightControllerActive )
		{
			g_pInput->GenerateHaptic( g_hapticAction->xrActionHandle, g_hapticAction->vecSubactionpaths[ 1 ], unDuration );
		}
	}

	// update xray assets visibility
	UpdateXrayAssetsVisibility();
}

inline void ActionSetEyeGazeIsActive( oxr::Action *pAction, uint32_t unActionStateIndex )
{
	if ( g_extEyeGaze )
	{
		g_bEyeGazeActive = pAction->vecActionStates[ unActionStateIndex ].statePose.isActive;
		return;
	}

	g_bEyeGazeActive = false;
}

inline void ActionSetEyeGazeBackup( oxr::Action *pAction, uint32_t unActionStateIndex )
{
	// callback placeholder - we don't need to do anything with this info for this demo
	// todo: allow no callbacks (nullptr)
	return;
}

inline void ActionHaptic( oxr::Action *pAction, uint32_t unActionStateIndex )
{
	// Haptic params (these are also params of the GenerateHaptic() function
	// adding here for visibility
	uint64_t unDuration = XR_MIN_HAPTIC_DURATION;
	float fAmplitude = 0.5f;
	float fFrequency = XR_FREQUENCY_UNSPECIFIED;

	// Check if the action has subpaths
	if ( !pAction->vecSubactionpaths.empty() )
	{
		g_pInput->GenerateHaptic( pAction->xrActionHandle, pAction->vecSubactionpaths[ unActionStateIndex ], unDuration, fAmplitude, fFrequency );
	}
	else
	{
		g_pInput->GenerateHaptic( pAction->xrActionHandle, XR_NULL_PATH, unDuration, fAmplitude, fFrequency );
	}
}

/**
 * These are custom graphics pipelines we'll need for the demo
 */
void CreateStencilPipelines( uint32_t *outStencilPipelineIndex, uint32_t *outStencilFillPipelineIndex )
{
	assert( g_pRender->GetRenderPasses()[ 0 ] != VK_NULL_HANDLE );

	// Vertex bindings
	VkVertexInputBindingDescription vertexInputBinding = { 0, sizeof( vkglTF::Model::Vertex ), VK_VERTEX_INPUT_RATE_VERTEX };
	std::vector< VkVertexInputAttributeDescription > vertexInputAttributes = {
		{ 0, 0, VK_FORMAT_R32G32B32_SFLOAT, 0 },
		{ 1, 0, VK_FORMAT_R32G32B32_SFLOAT, sizeof( float ) * 3 },
		{ 2, 0, VK_FORMAT_R32G32_SFLOAT, sizeof( float ) * 6 },
		{ 3, 0, VK_FORMAT_R32G32_SFLOAT, sizeof( float ) * 8 },
		{ 4, 0, VK_FORMAT_R32G32B32A32_SFLOAT, sizeof( float ) * 10 },
		{ 5, 0, VK_FORMAT_R32G32B32A32_SFLOAT, sizeof( float ) * 14 },
		{ 6, 0, VK_FORMAT_R32G32B32A32_SFLOAT, sizeof( float ) * 18 } };
	VkPipelineVertexInputStateCreateInfo vertexInputStateCI {};
	vertexInputStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO;
	vertexInputStateCI.vertexBindingDescriptionCount = 1;
	vertexInputStateCI.pVertexBindingDescriptions = &vertexInputBinding;
	vertexInputStateCI.vertexAttributeDescriptionCount = static_cast< uint32_t >( vertexInputAttributes.size() );
	vertexInputStateCI.pVertexAttributeDescriptions = vertexInputAttributes.data();

	// Input assembly
	VkPipelineInputAssemblyStateCreateInfo inputAssemblyStateCI {};
	inputAssemblyStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO;
	inputAssemblyStateCI.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST;

	// Rasterizer
	VkPipelineRasterizationStateCreateInfo rasterizationStateCI {};
	rasterizationStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO;
	rasterizationStateCI.polygonMode = VK_POLYGON_MODE_FILL;
	rasterizationStateCI.cullMode = VK_CULL_MODE_NONE;
	rasterizationStateCI.frontFace = VK_FRONT_FACE_COUNTER_CLOCKWISE;
	rasterizationStateCI.depthClampEnable = VK_FALSE;
	rasterizationStateCI.rasterizerDiscardEnable = VK_FALSE;
	rasterizationStateCI.depthBiasEnable = VK_FALSE;
	rasterizationStateCI.depthBiasConstantFactor = 0;
	rasterizationStateCI.depthBiasClamp = 0;
	rasterizationStateCI.depthBiasSlopeFactor = 0;
	rasterizationStateCI.lineWidth = 1.0f;

	// Color blending
	VkPipelineColorBlendAttachmentState blendAttachmentState {};
	blendAttachmentState.colorWriteMask = VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT | VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT;
	blendAttachmentState.blendEnable = VK_FALSE;

	VkPipelineColorBlendStateCreateInfo colorBlendStateCI {};
	colorBlendStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO;
	colorBlendStateCI.attachmentCount = 1;
	colorBlendStateCI.pAttachments = &blendAttachmentState;
	colorBlendStateCI.logicOpEnable = VK_FALSE;
	colorBlendStateCI.logicOp = VK_LOGIC_OP_NO_OP;
	colorBlendStateCI.blendConstants[ 0 ] = 1.0f;
	colorBlendStateCI.blendConstants[ 1 ] = 1.0f;
	colorBlendStateCI.blendConstants[ 2 ] = 1.0f;
	colorBlendStateCI.blendConstants[ 3 ] = 1.0f;

	// Viewport
	VkRect2D scissor = { { 0, 0 }, g_pRender->vkExtent };
	VkViewport viewport = { 0.0f, 0.0f, ( float )g_pRender->vkExtent.width, ( float )g_pRender->vkExtent.height, 0.0f, 1.0f };
	VkPipelineViewportStateCreateInfo viewportStateCI {};
	viewportStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO;
	viewportStateCI.viewportCount = 1;
	viewportStateCI.pViewports = &viewport;
	viewportStateCI.scissorCount = 1;
	viewportStateCI.pScissors = &scissor;

	// TODO: MSAA support
	VkPipelineMultisampleStateCreateInfo multisampleStateCI {};
	multisampleStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO;
	multisampleStateCI.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT;

	// TODO: Expose Dynamics states to apps
	std::vector< VkDynamicState > dynamicStateEnables; // = { VK_DYNAMIC_STATE_VIEWPORT, VK_DYNAMIC_STATE_SCISSOR };
	VkPipelineDynamicStateCreateInfo dynamicStateCI {};
	dynamicStateCI.sType = VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO;
	dynamicStateCI.pDynamicStates = dynamicStateEnables.data();
	dynamicStateCI.dynamicStateCount = static_cast< uint32_t >( dynamicStateEnables.size() );

	// Depth and stencil
	VkPipelineDepthStencilStateCreateInfo depthStencilStateCI { VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO };
	rasterizationStateCI.cullMode = VK_CULL_MODE_NONE;
	depthStencilStateCI.depthWriteEnable = VK_TRUE;
	depthStencilStateCI.depthTestEnable = VK_TRUE;
	depthStencilStateCI.depthCompareOp = VK_COMPARE_OP_LESS_OR_EQUAL;

	// Graphics Pipeline setup
	VkGraphicsPipelineCreateInfo pipelineCI { VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO };
	pipelineCI.renderPass = g_pRender->GetRenderPasses()[ 0 ];
	pipelineCI.subpass = 0;
	pipelineCI.pInputAssemblyState = &inputAssemblyStateCI;
	pipelineCI.pDepthStencilState = &depthStencilStateCI;
	pipelineCI.pTessellationState = nullptr;
	pipelineCI.pRasterizationState = &rasterizationStateCI;
	pipelineCI.pColorBlendState = &colorBlendStateCI;
	pipelineCI.pMultisampleState = &multisampleStateCI;
	pipelineCI.pViewportState = &viewportStateCI;

	// We'll create two pipelines with just variations in stencil handling

	// stencil pass
	pipelineCI.layout = g_pRender->vkPipelineLayout;
	pipelineCI.pVertexInputState = &vertexInputStateCI;
	rasterizationStateCI.cullMode = VK_CULL_MODE_BACK_BIT;

	// rasterizationState.cullMode = VK_CULL_MODE_NONE;
	depthStencilStateCI.depthTestEnable = VK_FALSE;
	depthStencilStateCI.stencilTestEnable = VK_TRUE;
	depthStencilStateCI.back.compareOp = VK_COMPARE_OP_ALWAYS;
	depthStencilStateCI.back.failOp = VK_STENCIL_OP_REPLACE;
	depthStencilStateCI.back.depthFailOp = VK_STENCIL_OP_REPLACE;
	depthStencilStateCI.back.passOp = VK_STENCIL_OP_REPLACE;
	depthStencilStateCI.back.compareMask = 0xff;
	depthStencilStateCI.back.writeMask = 0xff;
	depthStencilStateCI.back.reference = 1;
	depthStencilStateCI.front = depthStencilStateCI.back;

	*outStencilPipelineIndex = g_pRender->AddCustomPipeline( "shaders/pbr.vert.spv", "shaders/pbr_khr.frag.spv", &pipelineCI );

	// stencil fill pass
	depthStencilStateCI.back.compareOp = VK_COMPARE_OP_EQUAL;
	depthStencilStateCI.back.failOp = VK_STENCIL_OP_KEEP;
	depthStencilStateCI.back.depthFailOp = VK_STENCIL_OP_KEEP;
	depthStencilStateCI.back.passOp = VK_STENCIL_OP_REPLACE;
	depthStencilStateCI.front = depthStencilStateCI.back;
	depthStencilStateCI.depthTestEnable = VK_TRUE;
	*outStencilFillPipelineIndex = g_pRender->AddCustomPipeline( "shaders/pbr.vert.spv", "shaders/pbr_khr.frag.spv", &pipelineCI );
}

uint32_t CreateStencilRenderPipeline()
{
	VkDescriptorSetLayoutBinding setLayoutBinding {};
	setLayoutBinding.descriptorType = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
	setLayoutBinding.stageFlags = VK_SHADER_STAGE_VERTEX_BIT;
	setLayoutBinding.binding = 0;
	setLayoutBinding.descriptorCount = 1;

	std::vector< VkDescriptorSetLayoutBinding > vecLayoutBindings = { setLayoutBinding };
	return g_pRender->AddCustomlayout( vecLayoutBindings );
}

/**
 * These are utility functions to check game loop conditions
 * For android, we need to be able to check the app state as well
 * so we can process android events data at the appropriate times.
 */
#ifdef XR_USE_PLATFORM_ANDROID
static void app_handle_cmd( struct android_app *app, int32_t cmd )
{
	oxr::AndroidAppState *appState = ( oxr::AndroidAppState * )app->userData;

	switch ( cmd )
	{
		case APP_CMD_RESUME:
		{
			appState->Resumed = true;
			break;
		}
		case APP_CMD_PAUSE:
		{
			appState->Resumed = false;
			break;
		}
		case APP_CMD_DESTROY:
		{
			appState->NativeWindow = NULL;
			break;
		}
		case APP_CMD_INIT_WINDOW:
		{
			appState->NativeWindow = app->window;
			break;
		}
		case APP_CMD_TERM_WINDOW:
		{
			appState->NativeWindow = NULL;
			break;
		}
	}
}

bool CheckGameLoopExit( oxr::Provider *oxrProvider ) { return oxrProvider->Instance()->androidApp->onAppCmd = app_handle_cmd; }

#else
bool CheckGameLoopExit( oxr::Provider *oxrProvider ) { return oxrProvider->Session()->GetState() != XR_SESSION_STATE_EXITING; }
#endif

/**
 * These are callback functions that would be registered with the
 * openxr provider to handle render calls at appropriate times in
 * the application.
 */
void PreRender_Callback( uint32_t unSwapchainIndex, uint32_t unImageIndex )
{
	if ( g_xrFrameState.shouldRender )
	{
		// Hand tracking updates - only if controllers aren't present
		UpdateHandTrackingPoses( &g_xrFrameState );

		// Gestures
		Clap();
		Pinch( XR_HAND_LEFT_EXT );
		Pinch( XR_HAND_RIGHT_EXT );

		// Render
		g_pRender->BeginRender( g_pSession, g_vecFrameLayerProjectionViews, &g_xrFrameState, unSwapchainIndex, unImageIndex, 0.1f, 10000.f );

		// fx
		SwitchHiddenWorldGraphicsPipelines();

		// Passthrough adjustments
		AdjustPassthroughSaturation();
	}
}

void PostRender_Callback( uint32_t unSwapchainIndex, uint32_t unImageIndex ) { g_pRender->EndRender(); }
