/* Copyright 2021, 2022, 2023 Rune Berg (GitHub: https://github.com/1runeberg, Twitter: https://twitter.com/1runeberg, YouTube: https://www.youtube.com/@1RuneBerg)
 *
 *  SPDX-License-Identifier: MIT
 *
 *  Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
 *
 *  1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 *
 *  2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the
 *     documentation and/or other materials provided with the distribution.
 *
 *  3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this
 *     software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 *  THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS
 *  BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
 *  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 *  LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
 *  DAMAGE.
 *
 */

// App defines
#define APP_NAME "sample_06_finger_painting"
#define ENGINE_NAME "openxr_provider"
#define LOG_CATEGORY_DEMO "OpenXRProviderDemo"

// Generated by cmake by populating project_config.h.in
#include "project_config.h"

#include <cstdlib>
#include <iomanip>
#include <iostream>

#include <openxr_provider.h>
#include <xrvk/xrvk.hpp>

#include "xrvk/xrvk.hpp"

// global vars
XrEventDataBaseHeader *g_xrEventDataBaseheader = nullptr;

std::unique_ptr< xrvk::Render > g_pRender = nullptr;

oxr::Session *g_pSession = nullptr;
oxr::ExtHandTracking *g_extHandTracking = nullptr;
oxr::ExtFBPassthrough *g_extFBPassthrough = nullptr;

XrSessionState g_sessionState = XR_SESSION_STATE_UNKNOWN;
XrFrameState m_xrFrameState { XR_TYPE_FRAME_STATE };
std::vector< XrCompositionLayerProjectionView > g_vecFrameLayerProjectionViews;
std::vector< XrCompositionLayerBaseHeader * > g_vecFrameLayers;

bool g_bSkyboxScalingActivated = false;
float g_fSkyboxScaleGestureDistanceOnActivate = 0.0f;

bool g_bSaturationAdjustmentActivated = false;
float g_fSaturationValueOnActivation = 0.0f;

static const float k_fGestureActivationThreshold = 0.025f;
static const float k_fSkyboxScalingStride = 0.05f;
static const float k_fSaturationAdjustmentStride = 0.f;

// Color constants for finger painting
constexpr XrVector3f colorRed { 1, 0, 0 };
constexpr XrVector3f colorGreen { 0, 1, 0 };
constexpr XrVector3f colorBlue { 0, 0, 1 };
constexpr XrVector3f colorPurple { 1, 0, 1 };
constexpr XrVector3f colorYellow { 1, 1, 0 };
constexpr XrVector3f colorCyan { 0, 1, 1 };

// Cube vertices for finger painting
constexpr XrVector3f LBB { -0.5f, -0.5f, -0.5f };
constexpr XrVector3f LBF { -0.5f, -0.5f, 0.5f };
constexpr XrVector3f LTB { -0.5f, 0.5f, -0.5f };
constexpr XrVector3f LTF { -0.5f, 0.5f, 0.5f };
constexpr XrVector3f RBB { 0.5f, -0.5f, -0.5f };
constexpr XrVector3f RBF { 0.5f, -0.5f, 0.5f };
constexpr XrVector3f RTB { 0.5f, 0.5f, -0.5f };
constexpr XrVector3f RTF { 0.5f, 0.5f, 0.5f };

std::vector< Shapes::Vertex > g_vecPaintCubeVertices = {
	CUBE_SIDE( LTB, LBF, LBB, LTB, LTF, LBF, colorCyan ) // -X
	CUBE_SIDE( RTB, RBB, RBF, RTB, RBF, RTF, colorCyan ) // +X
	CUBE_SIDE( LBB, LBF, RBF, LBB, RBF, RBB, colorCyan ) // -Y
	CUBE_SIDE( LTB, RTB, RTF, LTB, RTF, LTF, colorCyan ) // +Y
	CUBE_SIDE( LBB, RBB, RTB, LBB, RTB, LTB, colorCyan ) // -Z
	CUBE_SIDE( LBF, LTF, RTF, LBF, RTF, RBF, colorCyan ) // +Z
};

// Reference shape for painting
Shapes::Shape *g_pReferencePaint = nullptr;

/**
 * These are utility functions for the extensions we will be using in this demo
 */
void PopulateHandShapes( Shapes::Shape *shapePalm )
{
	assert( g_pRender );
	assert( shapePalm );

	// a cube per joint per hand - we'll match the indices with the hand tracking extension's
	// so we can easily refer to them later on to update the current tracked poses
	uint32_t unTotalHandJoints = XR_HAND_JOINT_COUNT_EXT * 2;
	g_pRender->vecShapes.resize( unTotalHandJoints );

	// zero out the scale so cubes won't immediately appear until after the first frame of poses come in
	shapePalm->scale = { 0.0f, 0.0f, 0.0f };

	// XR_HAND_JOINT_PALM_EXT (0) - Use as a reference
	g_pRender->vecShapes[ XR_HAND_JOINT_PALM_EXT ] = shapePalm;

	// left hand will use the first XR_HAND_JOINT_COUNT_EXT indices
	// right hand will use specHandJointIndex + XR_HAND_JOINT_COUNT_EXT indices
	for ( uint32_t i = 1; i < unTotalHandJoints; i++ )
	{
		g_pRender->vecShapes[ i ] = shapePalm->Duplicate();
	}
}

void UpdateHandJoints( XrHandEXT hand, XrHandJointLocationEXT *handJoints )
{
	uint8_t unOffset = hand == XR_HAND_LEFT_EXT ? 0 : XR_HAND_JOINT_COUNT_EXT;

	for ( uint32_t i = 0; i < XR_HAND_JOINT_COUNT_EXT; i++ )
	{
		if ( ( handJoints[ i ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
		{
			g_pRender->vecShapes[ i + unOffset ]->pose = handJoints[ i ].pose;
			g_pRender->vecShapes[ i + unOffset ]->scale = { handJoints[ i ].radius, handJoints[ i ].radius, handJoints[ i ].radius };
		}
	}
}

void UpdateHandTrackingPoses( XrFrameState *frameState )
{
	if ( g_extHandTracking )
	{
		// Update the hand joints poses for this frame
		g_extHandTracking->LocateHandJoints( XR_HAND_LEFT_EXT, g_pSession->GetAppSpace(), frameState->predictedDisplayTime );
		g_extHandTracking->LocateHandJoints( XR_HAND_RIGHT_EXT, g_pSession->GetAppSpace(), frameState->predictedDisplayTime );

		// Retrieve updated hand poses
		XrHandJointLocationsEXT *leftHand = g_extHandTracking->GetHandJointLocations( XR_HAND_LEFT_EXT );
		XrHandJointLocationsEXT *rightHand = g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT );

		// Finally, update cube poses representing the hand joints
		if ( leftHand->isActive )
			UpdateHandJoints( XR_HAND_LEFT_EXT, leftHand->jointLocations );

		if ( rightHand->isActive )
			UpdateHandJoints( XR_HAND_RIGHT_EXT, g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT )->jointLocations );
	}
}

void UpdatePaintColor( XrVector3f *newColor )
{
	for ( auto &cubeVertices : g_vecPaintCubeVertices )
	{
		cubeVertices.Color = *newColor;
	}
}

void Paint( XrHandEXT hand )
{
	// Check if hand tracking is available
	if ( g_extHandTracking )
	{
		// Get latest hand joints
		XrHandJointLocationsEXT *joints = g_extHandTracking->GetHandJointLocations( hand );

		// Check if index tip and thumb tips have valid locations
		if ( joints->isActive && ( joints->jointLocations[ XR_HAND_JOINT_INDEX_TIP_EXT ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
			 ( joints->jointLocations[ XR_HAND_JOINT_THUMB_TIP_EXT ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
		{
			// Paint gesture - if index and thumb tips meet
			float fDistance = 0.0f;
			XrVector3f_Distance( &fDistance, &joints->jointLocations[ XR_HAND_JOINT_INDEX_TIP_EXT ].pose.position, &joints->jointLocations[ XR_HAND_JOINT_THUMB_TIP_EXT ].pose.position );

			if ( fDistance < k_fGestureActivationThreshold )
			{
				// Paint from the index tip
				Shapes::Shape *newPaint = g_pReferencePaint->Duplicate();
				newPaint->pose = joints->jointLocations[ XR_HAND_JOINT_INDEX_TIP_EXT ].pose;
				g_pRender->vecShapes.push_back( newPaint );
			}
		}
	}
}

bool IsTwoHandedGestureActive( 
	XrHandJointEXT leftJointA, XrHandJointEXT leftJointB,
	XrHandJointEXT rightJointA, XrHandJointEXT rightJointB,
	XrVector3f *outReferencePosition_Left,	XrVector3f *outReferencePosition_Right, 
	bool *outActivated, float* fCacheValue )
{
	// Check if hand tracking is available
	if ( g_extHandTracking )
	{
		// Get latest hand joints
		XrHandJointLocationsEXT *leftHand = g_extHandTracking->GetHandJointLocations( XR_HAND_LEFT_EXT );
		XrHandJointLocationsEXT *rightHand = g_extHandTracking->GetHandJointLocations( XR_HAND_RIGHT_EXT );

		XrHandJointLocationEXT *leftJoints = leftHand->jointLocations;
		XrHandJointLocationEXT *rightJoints = rightHand->jointLocations;

		// Check if both left and right hands are tracking
		// and the provided joint a and joint b on both hands have valid positions
		if ( leftHand->isActive && rightHand->isActive && 
		   ( leftJoints[ leftJointA ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
		   ( leftJoints[ leftJointB ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
		   ( rightJoints[ rightJointA ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 &&
		   ( rightJoints[ rightJointB ].locationFlags & XR_SPACE_LOCATION_POSITION_VALID_BIT ) != 0 )
		{
			// Check gesture
			float fDistance = 0.0f;

			*outReferencePosition_Left = leftJoints[ leftJointB ].pose.position;
			XrVector3f_Distance( &fDistance, &leftJoints[ leftJointA ].pose.position, outReferencePosition_Left );

			if ( fDistance < k_fGestureActivationThreshold )
			{
				*outReferencePosition_Right = rightJoints[ rightJointB ].pose.position;
				XrVector3f_Distance( &fDistance, &rightJoints[ rightJointA ].pose.position, outReferencePosition_Right );

				if ( fDistance < k_fGestureActivationThreshold )
				{
					*outActivated = true;
					return true;
				}
			}
		}
	}

	*outActivated = false;
	*fCacheValue = 0.0f;
	return false;
}

bool IsSkyboxScalingActive( XrVector3f *outThumbPosition_Left, XrVector3f *outThumbPosition_Right )
{
	// Gesture - middle and thumb tips are touching on both hands
	return IsTwoHandedGestureActive(XR_HAND_JOINT_MIDDLE_TIP_EXT, XR_HAND_JOINT_THUMB_TIP_EXT, XR_HAND_JOINT_MIDDLE_TIP_EXT, XR_HAND_JOINT_THUMB_TIP_EXT,
		outThumbPosition_Left, outThumbPosition_Right, &g_bSkyboxScalingActivated, &g_fSkyboxScaleGestureDistanceOnActivate );
}

bool IsSaturationAdjustmentActive( XrVector3f *outThumbPosition_Left, XrVector3f *outThumbPosition_Right )
{
	// Gesture - ring and thumb tips are touching on both hands
	return IsTwoHandedGestureActive(XR_HAND_JOINT_RING_TIP_EXT, XR_HAND_JOINT_THUMB_TIP_EXT, XR_HAND_JOINT_RING_TIP_EXT, XR_HAND_JOINT_THUMB_TIP_EXT,
									outThumbPosition_Left, outThumbPosition_Right, &g_bSaturationAdjustmentActivated, &g_fSkyboxScaleGestureDistanceOnActivate );
}

void ScaleSkybox()
{
	// Check if gesture was activated on a previous frame
	bool bGestureActivedOnPreviousFrame = g_bSkyboxScalingActivated;

	// Check if gesture is active in this frame
	XrVector3f leftThumb, rightThumb;
	if ( IsSkyboxScalingActive( &leftThumb, &rightThumb ) )
	{
		// Gesture was activated on this frame, cache the distance
		if ( !bGestureActivedOnPreviousFrame )
		{
			XrVector3f_Distance( &g_fSkyboxScaleGestureDistanceOnActivate, &leftThumb, &rightThumb );
		}

		// Scale skybox based on distance and stride
		float currentDistance = 0.0f;
		XrVector3f_Distance( &currentDistance, &leftThumb, &rightThumb );

        float fGestureDistanceFromPreviousFrame = currentDistance - g_fSkyboxScaleGestureDistanceOnActivate;
		if (abs(fGestureDistanceFromPreviousFrame ) < k_fSkyboxScalingStride )
			return;

		float fScaleFactor = fGestureDistanceFromPreviousFrame * k_fSkyboxScalingStride;
		g_pRender->skybox->currentScale.x += fScaleFactor;
		g_pRender->skybox->currentScale.y = g_pRender->skybox->currentScale.z = g_pRender->skybox->currentScale.x;
	}
}

/**
 * These are utility functions to check game loop conditions
 * For android, we need to be able to check the app state as well
 * so we can process android events data at the appropriate times.
 */
#ifdef XR_USE_PLATFORM_ANDROID
static void app_handle_cmd( struct android_app *app, int32_t cmd )
{
	oxr::AndroidAppState *appState = ( oxr::AndroidAppState * )app->userData;

	switch ( cmd )
	{
		case APP_CMD_RESUME:
		{
			appState->Resumed = true;
			break;
		}
		case APP_CMD_PAUSE:
		{
			appState->Resumed = false;
			break;
		}
		case APP_CMD_DESTROY:
		{
			appState->NativeWindow = NULL;
			break;
		}
		case APP_CMD_INIT_WINDOW:
		{
			appState->NativeWindow = app->window;
			break;
		}
		case APP_CMD_TERM_WINDOW:
		{
			appState->NativeWindow = NULL;
			break;
		}
	}
}

bool CheckGameLoopExit( oxr::Provider *oxrProvider ) { return oxrProvider->Instance()->androidApp->onAppCmd = app_handle_cmd; }

#else
bool CheckGameLoopExit( oxr::Provider *oxrProvider ) { return oxrProvider->Session()->GetState() != XR_SESSION_STATE_EXITING; }
#endif

/**
 * These are callback functions that would be registered with the
 * openxr provider to handle render calls at appropriate times in
 * the application.
 */
void PreRender_Callback( uint32_t unSwapchainIndex, uint32_t unImageIndex )
{
	if ( m_xrFrameState.shouldRender )
	{
		// Hand tracking updates
		UpdateHandTrackingPoses( &m_xrFrameState );

		// Painting updates
		Paint( XR_HAND_LEFT_EXT );
		Paint( XR_HAND_RIGHT_EXT );

		// Skybox scaling
		ScaleSkybox();

		// Render
		g_pRender->BeginRender( g_pSession, g_vecFrameLayerProjectionViews, &m_xrFrameState, unSwapchainIndex, unImageIndex, 0.1f, 10000.f );
	}
}

void PostRender_Callback( uint32_t unSwapchainIndex, uint32_t unImageIndex ) { g_pRender->EndRender(); }

/**
 * This is the application openxr flow and is numbered
 * with distinct steps that correlates to the openxr
 * application lifecycle.
 */
#ifdef XR_USE_PLATFORM_ANDROID
XrResult demo_openxr_start( struct android_app *app )
#else
XrResult demo_openxr_start()
#endif
{
	// (1) Create a openxr provider object that we'll use to communicate with the openxr runtime.
	//     You can optionally set a default log level during creation.
	std::unique_ptr< oxr::Provider > oxrProvider = std::make_unique< oxr::Provider >( oxr::ELogLevel::LogDebug );

	// For Android, we need to first initialize the android openxr loader
#ifdef XR_USE_PLATFORM_ANDROID
	if ( !XR_UNQUALIFIED_SUCCESS( oxrProvider->InitAndroidLoader( app ) ) )
	{
		oxr::LogError( LOG_CATEGORY_DEMO, "FATAL! Unable to load Android OpenXR Loader in this device!" );
		return XR_ERROR_RUNTIME_UNAVAILABLE;
	}
#endif

	// (2) Check requested extensions against supported extensions from the current runtime
	//     We will use this later when initializing an openxr instance
	//     In this sample, we'll try to check for and enable some useful extensions if available:
	//     https://registry.khronos.org/OpenXR/specs/1.0/html/xrspec.html#XR_KHR_visibility_mask
	//	   https://registry.khronos.org/OpenXR/specs/1.0/html/xrspec.html#XR_KHR_composition_layer_depth
	//     https://registry.khronos.org/OpenXR/specs/1.0/html/xrspec.html#XR_EXT_dpad_binding
	//
	// 	   If you do not specify a vulkan graphics api extension, then the provider will choose the best one
	//     from what's available from the runtime. In this case, you can use GetCurrentVulkanExt() check which
	//
	//	   You can also manually request available runtime extensions with GetSupportedExtensions()
	//     Similar functions are available for api layers

	std::vector< const char * > vecRequestedExtensions {
		// These extensions, being KHR, are very likely to be supported by most major runtimes
		XR_KHR_VULKAN_ENABLE_EXTENSION_NAME,   // this is our preferred graphics extension (only vulkan is supported)
		XR_KHR_VISIBILITY_MASK_EXTENSION_NAME, // this gives us a stencil mask area that the end user will never see, so we don't need to render to it

		XR_EXT_HAND_TRACKING_EXTENSION_NAME, // Multi-vendor extension but may have different behaviors/implementations across runtimes
		XR_FB_PASSTHROUGH_EXTENSION_NAME	 // Vendor specific extension - not supported on all runtimes
	};

	oxrProvider->FilterOutUnsupportedExtensions( vecRequestedExtensions );

	// (3) Set the application info that the openxr runtime will need in order to initialize an openxr instance
	//     including the supported extensions we found earlier
	oxr::AppInstanceInfo oxrAppInstanceInfo {};
	oxrAppInstanceInfo.sAppName = APP_NAME;
	oxrAppInstanceInfo.unAppVersion = OXR_MAKE_VERSION32( SAMPLE6_VERSION_MAJOR, SAMPLE6_VERSION_MINOR, SAMPLE6_VERSION_PATCH );
	oxrAppInstanceInfo.sEngineName = ENGINE_NAME;
	oxrAppInstanceInfo.unEngineVersion = OXR_MAKE_VERSION32( PROVIDER_VERSION_MAJOR, PROVIDER_VERSION_MINOR, PROVIDER_VERSION_PATCH );
	oxrAppInstanceInfo.vecInstanceExtensions = vecRequestedExtensions;

	// (4) Initialize the provider - this will create an openxr instance with the current default openxr runtime.
	//     If there's no runtime or something has gone wrong, the provider will return an error code
	//			from https://registry.khronos.org/OpenXR/specs/1.0/html/xrspec.html#return-codes
	//     Notice that you can also use native openxr data types (e.g. XrResult) directly

	XrResult xrResult = oxrProvider->Init( &oxrAppInstanceInfo );
	if ( !XR_UNQUALIFIED_SUCCESS( xrResult ) )
		return xrResult;

		// (5) Setup the vulkan renderer and create an openxr graphics binding
#ifdef XR_USE_PLATFORM_ANDROID
	g_pRender = std::make_unique< xrvk::Render >( oxrProvider->Instance()->androidActivity->assetManager, xrvk::ELogLevel::LogVerbose );
#else
	g_pRender = std::make_unique< xrvk::Render >( xrvk::ELogLevel::LogVerbose );
#endif

	xrResult = g_pRender->Init( oxrProvider.get(), oxrAppInstanceInfo.sAppName.c_str(), oxrAppInstanceInfo.unAppVersion, oxrAppInstanceInfo.sEngineName.c_str(), oxrAppInstanceInfo.unEngineVersion );

	if ( !XR_UNQUALIFIED_SUCCESS( xrResult ) )
		return xrResult;

	// (6) Create an openxr session
	xrResult = oxrProvider->CreateSession( g_pRender->GetVulkanGraphicsBinding() );
	if ( !XR_UNQUALIFIED_SUCCESS( xrResult ) )
		return xrResult;

	g_pSession = oxrProvider->Session();

	// (6.1) Get any extensions that requires an active openxr instance and session
	g_extHandTracking = static_cast< oxr::ExtHandTracking * >( oxrProvider->Instance()->extHandler.GetExtension( XR_EXT_HAND_TRACKING_EXTENSION_NAME ) );
	if ( g_extHandTracking )
	{
		xrResult = g_extHandTracking->Init();
	}

	g_extFBPassthrough = static_cast< oxr::ExtFBPassthrough * >( oxrProvider->Instance()->extHandler.GetExtension( XR_FB_PASSTHROUGH_EXTENSION_NAME ) );
	// Initialize any extensions we need
	if ( g_extFBPassthrough && g_pSession->GetAppSpace() != XR_NULL_HANDLE )
	{
		if ( XR_UNQUALIFIED_SUCCESS( g_extFBPassthrough->Init( g_pSession->GetAppSpace() ) ) )
			g_extFBPassthrough->SetPassThroughStyle( oxr::ExtFBPassthrough::EPassthroughMode::EPassthroughMode_GreenRampYellowEdges );
	}
	// (7) Create swapchains for rendering

	// (7.1) Specify color formats
#ifdef XR_USE_PLATFORM_ANDROID
	std::vector< int64_t > vecRequestedTextureFormats = { VK_FORMAT_R8G8B8A8_SRGB };
#else
	std::vector< int64_t > vecRequestedTextureFormats; // we'll send an empty one and let the provider choose from the runtime's supported color formats
#endif

	// (7.2) Specify depth formats
	std::vector< int64_t > vecRequestedDepthFormats = { VK_FORMAT_D24_UNORM_S8_UINT }; // we'll send an empty one and let the provider choose from the runtime's supported depth formats

	// (7.3) Create swapchains - selected texture formats will contain the texture formats selected from the requested ones (provider will choose if no preferences were sent)
	oxr::TextureFormats selectedTextureFormats { VK_FORMAT_UNDEFINED, VK_FORMAT_UNDEFINED };
	xrResult = oxrProvider->Session()->CreateSwapchains( &selectedTextureFormats, vecRequestedTextureFormats, vecRequestedDepthFormats );
	if ( !XR_UNQUALIFIED_SUCCESS( xrResult ) )
		return xrResult;

	// (8) Prepare vulkan resources for rendering - this creates the command buffers and render passes

	// (8.1) Set texture extent
	VkExtent2D vkExtent;
	vkExtent.width = oxrProvider->Session()->GetSwapchains()[ 0 ].unWidth;
	vkExtent.height = oxrProvider->Session()->GetSwapchains()[ 0 ].unHeight;

	// (8.2) Initialize render resources
	g_pRender->CreateRenderResources( g_pSession, selectedTextureFormats.vkColorTextureFormat, selectedTextureFormats.vkDepthTextureFormat, vkExtent );

	// (8.3) Optional: Add any shape pipelines
	if ( g_extHandTracking )
	{
		// For hand tracking cubes
		Shapes::Shape_Cube cubePalmLeft {};
		g_pRender->PrepareShapesPipeline( &cubePalmLeft, "shaders/shape.vert.spv", "shaders/shape.frag.spv" );

		PopulateHandShapes( &cubePalmLeft );

		// For painting cubes
		g_pReferencePaint = new Shapes::Shape_Cube;
		g_pReferencePaint->vecVertices = &g_vecPaintCubeVertices;
		g_pReferencePaint->scale = { 0.01f, 0.01f, 0.01f };

		g_pRender->PrepareShapesPipeline( g_pReferencePaint, "shaders/shape.vert.spv", "shaders/shape.frag.spv" );
	}

	// (8.3) Add Render Scenes to render (will spawn in world origin)
	g_pRender->AddRenderScene( "models/Box.glb", { 1.0f, 1.0f, 0.1f } );
	// g_pRender->AddRenderModel( "models/test_sphere.glb", { .01f, .01f, .01f } );
	// g_pRender->AddRenderScene( "models/openxr_proxy_right.glb", { .1f, .1f, .1f } );

	// (8.4) Add Render Sectors and Render Models (will spawn based on defined reference space and/or offsets from world origin)
	XrSpace spaceFront;
	oxrProvider->Session()->CreateReferenceSpace( &spaceFront, XR_REFERENCE_SPACE_TYPE_STAGE, { { 0.0f, 0.0f, 0.0f, 1.0f }, { 0.0f, -3.0f, -1.0f } } ); // 3m down, no rotation

	// XrSpace spaceLeft;
	// oxrProvider->Session()->CreateReferenceSpace( &spaceLeft, XR_REFERENCE_SPACE_TYPE_STAGE, { { 0.5f, 0.5f, -0.5f, 0.5f }, { -1.0f, 1.0f, 0.0f } } ); // 1m left 1m up, rotated x: 90, y: 0, z: 90

	// g_pRender->AddRenderModel( "models/DamagedHelmet.glb", { 0.25f, 0.25f, 0.25f }, spaceLeft );
	// g_pRender->AddRenderSector( "models/EnvironmentTest/EnvironmentTest.gltf", { 0.2f, 0.2f, 0.2f }, spaceFront );

	// (8.5) Optional - Set vismask if present
	oxr::ExtVisMask *pVisMask = static_cast< oxr::ExtVisMask * >( oxrProvider->Instance()->extHandler.GetExtension( XR_KHR_VISIBILITY_MASK_EXTENSION_NAME ) );

	if ( pVisMask )
	{
		g_pRender->CreateVisMasks( 2 );

		pVisMask->GetVisMask(
			g_pRender->GetVisMasks()[ 0 ].vertices, g_pRender->GetVisMasks()[ 0 ].indices, XR_VIEW_CONFIGURATION_TYPE_PRIMARY_STEREO, 0, XR_VISIBILITY_MASK_TYPE_HIDDEN_TRIANGLE_MESH_KHR );

		pVisMask->GetVisMask(
			g_pRender->GetVisMasks()[ 1 ].vertices, g_pRender->GetVisMasks()[ 1 ].indices, XR_VIEW_CONFIGURATION_TYPE_PRIMARY_STEREO, 1, XR_VISIBILITY_MASK_TYPE_HIDDEN_TRIANGLE_MESH_KHR );
	}

	// (8.6) Optional - Set skybox
	g_pRender->skybox->currentScale = { 5.0f, 5.0f, 5.0f };
	g_pRender->skybox->bApplyOffset = true;
	g_pRender->skybox->offsetRotation = { 0.0f, 0.0f, 1.0f, 0.0f }; // rotate 180 degrees in z (roll)

	// (9) Start loading gltf assets from disk
	g_pRender->LoadAssets();
	g_pRender->PrepareAllPipelines();

	// (10) Register render callbacks
	//      We'll build the command buffers after acquire and submit to the queue after wait
	//      to ensure that the runtime isn't using VkQueue at the same time (most runtimes don't)
	oxr::RenderImageCallback releaseCallback;
	releaseCallback.fnCallback = PreRender_Callback;
	oxrProvider->Session()->RegisterWaitSwapchainImageImageCallback( &releaseCallback );

	oxr::RenderImageCallback waitCallback;
	waitCallback.fnCallback = PostRender_Callback;
	oxrProvider->Session()->RegisterWaitSwapchainImageImageCallback( &waitCallback );

	// (11) Set other platform callbacks
#ifdef XR_USE_PLATFORM_ANDROID
	oxrProvider->Instance()->androidApp->onAppCmd = app_handle_cmd;
#endif

	// Main game loop
	bool bProcessRenderFrame = false;
	while ( CheckGameLoopExit( oxrProvider.get() ) )
	{
#ifdef XR_USE_PLATFORM_ANDROID
		// For android we need in addition, to poll android events to proceed to the session ready state
		while ( true )
		{
			// We'll wait indefinitely (-1ms) for android poll results until we get to the android app resumed state
			// and/or the openxr session has started.
			const int nTimeout = ( !oxrProvider->Instance()->androidAppState.Resumed && oxrProvider->Session()->IsSessionRunning() ) ? -1 : 0;

			int nEvents;
			struct android_poll_source *androidPollSource;
			if ( ALooper_pollAll( nTimeout, nullptr, &nEvents, ( void ** )&androidPollSource ) < 0 )
			{
				break;
			}

			// Process android event
			if ( androidPollSource )
			{
				androidPollSource->process( oxrProvider->Instance()->androidApp, androidPollSource );
			}
		}
#endif
		// (12) Poll runtime for openxr events
		g_xrEventDataBaseheader = oxrProvider->PollXrEvents();

		// Handle events
		if ( g_xrEventDataBaseheader )
		{
			// Handle session state changes
			if ( g_xrEventDataBaseheader->type == XR_TYPE_EVENT_DATA_SESSION_STATE_CHANGED )
			{
				g_sessionState = oxrProvider->Session()->GetState();

				if ( g_sessionState == XR_SESSION_STATE_READY )
				{
					// (12.1) Start session - begin the app's frame loop here
					oxr::LogInfo( LOG_CATEGORY_DEMO, "App frame loop starts here." );
					xrResult = oxrProvider->Session()->Begin();
					if ( xrResult == XR_SUCCESS ) // defaults to stereo (vr)
					{
						// Start processing render frames
						bProcessRenderFrame = true;
					}
					else
					{
						bProcessRenderFrame = false;
						oxr::LogError( LOG_CATEGORY_DEMO, "Unable to start openxr session (%s)", oxr::XrEnumToString( xrResult ) );
					}
				}
				else if ( g_sessionState == XR_SESSION_STATE_STOPPING )
				{
					// (12.2) End session - end the app's frame loop here
					oxr::LogInfo( LOG_CATEGORY_DEMO, "App frame loop ends here." );
					if ( oxrProvider->Session()->End() == XR_SUCCESS )
						bProcessRenderFrame = false;
				}
			}
		}

		// Render loop
		if ( bProcessRenderFrame )
		{
			// (13) Call render frame - this will call our registered callback at the appropriate times

			//  (13.1) Define projection layers to render
			XrCompositionLayerFlags xrCompositionLayerFlags = 0;
			g_vecFrameLayers.clear();
			if ( g_extFBPassthrough )
			{
				xrCompositionLayerFlags = XR_COMPOSITION_LAYER_BLEND_TEXTURE_SOURCE_ALPHA_BIT | XR_COMPOSITION_LAYER_CORRECT_CHROMATIC_ABERRATION_BIT | XR_COMPOSITION_LAYER_UNPREMULTIPLIED_ALPHA_BIT;

				g_vecFrameLayers.push_back( reinterpret_cast< XrCompositionLayerBaseHeader * >( g_extFBPassthrough->GetCompositionLayer() ) );
			}

			g_vecFrameLayerProjectionViews.resize( oxrProvider->Session()->GetSwapchains().size(), { XR_TYPE_COMPOSITION_LAYER_PROJECTION_VIEW } );
			oxrProvider->Session()->RenderFrame( g_vecFrameLayerProjectionViews, g_vecFrameLayers, &m_xrFrameState, xrCompositionLayerFlags );
		}
	}

	// (14) Cleanup
	g_pRender.release();
	oxrProvider.release();

	return xrResult;
}

/**
 * These are the main entry points for the application.
 * Note that the android entry point uses the android_native_app_glue and
 * runs on its own thread.
 */
#ifdef XR_USE_PLATFORM_ANDROID
void android_main( struct android_app *app )
{
	// Attach environment to thread
	JNIEnv *Env;
	app->activity->vm->AttachCurrentThread( &Env, nullptr );

	// Create instance
	demo_openxr_start( app );

	return;
}

#else
int main( int argc, char *argv[] )
{
	// Debugging
	std::cout << "Argument count [argc] == " << argc << '\n';
	for ( uint32_t i = 0; i != argc; ++i )
	{
		std::cout << "argv[" << i << "] == " << std::quoted( argv[ i ] ) << '\n';
	}
	std::cout << "argv[" << argc << "] == " << static_cast< void * >( argv[ argc ] ) << '\n';

	std::cout << "\n\nPress enter to start. This is also a good time to attach a debugger if you need to.";
	std::cin.get();

	// Create instance
	XrResult xrResult = demo_openxr_start();
	if ( !XR_UNQUALIFIED_SUCCESS( xrResult ) )
	{
		std::cout << "\nError running demo program with XrResult (" << xrResult << ")";
	}

	// Manual for debug sessions
	std::cout << "\n\nPress enter to end.";
	std::cin.get();

	return EXIT_SUCCESS;
}
#endif
